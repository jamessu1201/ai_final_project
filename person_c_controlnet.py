#!/usr/bin/env python3
"""
person_c_controlnet.py
Person C - ControlNet å¯¦é©—ä¸»ç¨‹å¼
ç²¾ç°¡é«˜æ•ˆç‰ˆï¼šä»Šå¤©å®Œæˆ
"""

import torch
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel
from PIL import Image
import cv2
import numpy as np
from pathlib import Path
import json
import time
from tqdm import tqdm
from prompts import PROMPTS

class ControlNetExperiment:
    def __init__(self, output_dir="results/person_c"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.results = []
        
        print(f"ğŸ® Using device: {self.device}")
        if torch.cuda.is_available():
            print(f"âœ… GPU: {torch.cuda.get_device_name(0)}")
    
    def load_model(self):
        """è¼‰å…¥ ControlNet æ¨¡å‹"""
        print("\n" + "="*60)
        print("ğŸ“¥ Loading ControlNet model...")
        print("="*60)
        
        try:
            # è¼‰å…¥ ControlNet
            print("Loading ControlNet Canny...")
            controlnet = ControlNetModel.from_pretrained(
                "lllyasviel/sd-controlnet-canny",
                torch_dtype=torch.float16,
                cache_dir="./models",
                local_files_only=False,
                use_safetensors=True,
            )
            
            # è¼‰å…¥ SD 1.5 pipeline
            print("Loading Stable Diffusion 1.5 pipeline...")
            self.pipe = StableDiffusionControlNetPipeline.from_pretrained(
                "runwayml/stable-diffusion-v1-5",
                controlnet=controlnet,
                torch_dtype=torch.float16,
                safety_checker=None,
                cache_dir="./models",
                local_files_only=False,
                use_safetensors=True,
            )
            
            # ç§»åˆ° GPU
            self.pipe = self.pipe.to(self.device)
            
            # å•Ÿç”¨è¨˜æ†¶é«”å„ªåŒ–
            if self.device == "cuda":
                self.pipe.enable_model_cpu_offload()
                self.pipe.enable_attention_slicing()
            
            print("âœ… Model loaded successfully!")
            
        except ImportError as e:
            print(f"âŒ Import Error: {e}")
            print("\nğŸ”§ Fixing dependencies...")
            print("Please run:")
            print("  pip install --upgrade transformers==4.30.0")
            print("  pip install --upgrade diffusers==0.21.0")
            print("  pip install --upgrade accelerate==0.20.0")
            raise
        except Exception as e:
            print(f"âŒ Error loading model: {e}")
            print("\nğŸ’¡ Tip: Make sure you've installed all dependencies!")
            raise
    
    def get_canny_edge(self, image_path, low_threshold=100, high_threshold=200):
        """å¾åœ–ç‰‡æå– Canny edges"""
        # è®€å–åœ–ç‰‡
        image = cv2.imread(str(image_path))
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = cv2.resize(image, (512, 512))
        
        # è½‰ç°éš
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        
        # Canny edge detection
        edges = cv2.Canny(gray, low_threshold, high_threshold)
        edges = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)
        
        # è½‰æˆ PIL Image
        canny_image = Image.fromarray(edges)
        
        return canny_image
    
    def generate(self, prompt, control_image, seed=42):
        """ä½¿ç”¨ ControlNet ç”Ÿæˆåœ–ç‰‡"""
        generator = torch.Generator(self.device).manual_seed(seed)
        
        start_time = time.time()
        
        with torch.no_grad():
            output = self.pipe(
                prompt=prompt,
                image=control_image,
                num_inference_steps=20,  # æ¸›å°‘æ­¥æ•¸åŠ å¿«é€Ÿåº¦
                guidance_scale=7.5,
                generator=generator,
                num_images_per_prompt=1,
            )
        
        gen_time = time.time() - start_time
        
        return output.images[0], gen_time
    
    def run_experiments(self, num_prompts=25):
        """
        åŸ·è¡Œ ControlNet å¯¦é©—
        num_prompts: è¦æ¸¬è©¦çš„ prompt æ•¸é‡ï¼ˆé è¨­25å€‹ï¼Œç´„1-2å°æ™‚ï¼‰
        """
        print("\n" + "="*60)
        print("ğŸš€ Starting ControlNet Experiments")
        print("="*60)
        
        # è¼‰å…¥æ¨¡å‹
        self.load_model()
        
        # å–å¾— control images
        control_dir = Path("control_images/simple_shapes")
        control_images = sorted(list(control_dir.glob("*.png")))
        
        if not control_images:
            print("âŒ No control images found!")
            return
        
        print(f"\nğŸ“¸ Found {len(control_images)} control images")
        print(f"ğŸ“ Will test {num_prompts} prompts")
        print(f"â±ï¸  Estimated time: {num_prompts * 30 / 60:.1f} minutes\n")
        
        # å°æ¯å€‹ control image æ¸¬è©¦å¤šå€‹ prompts
        prompts_per_control = num_prompts // len(control_images)
        
        total_generated = 0
        
        for ctrl_idx, ctrl_img_path in enumerate(control_images):
            print(f"\n{'='*60}")
            print(f"ğŸ¨ Control Image {ctrl_idx + 1}/{len(control_images)}: {ctrl_img_path.name}")
            print(f"{'='*60}")
            
            # ç”Ÿæˆ Canny edge
            print("  Extracting Canny edges...")
            canny_image = self.get_canny_edge(ctrl_img_path)
            canny_save_path = self.output_dir / f"canny_{ctrl_idx:03d}.png"
            canny_image.save(canny_save_path)
            
            # ç”¨é€™å€‹ control æ¸¬è©¦å¤šå€‹ prompts
            start_idx = ctrl_idx * prompts_per_control
            end_idx = min(start_idx + prompts_per_control, len(PROMPTS))
            test_prompts = PROMPTS[start_idx:end_idx]
            
            print(f"  Testing {len(test_prompts)} prompts...")
            
            for prompt_idx, prompt in enumerate(tqdm(test_prompts, desc=f"  {ctrl_img_path.stem}")):
                global_idx = start_idx + prompt_idx
                
                # ç”Ÿæˆåœ–ç‰‡
                image, gen_time = self.generate(prompt, canny_image, seed=42+global_idx)
                
                # å„²å­˜çµæœ
                save_path = self.output_dir / f"controlnet_{global_idx:03d}.png"
                image.save(save_path)
                
                # è¨˜éŒ„çµæœ
                self.results.append({
                    "model": "ControlNet-Canny",
                    "control_image": str(ctrl_img_path),
                    "canny_image": str(canny_save_path),
                    "prompt": prompt,
                    "prompt_index": global_idx,
                    "generation_time": gen_time,
                    "image_path": str(save_path),
                })
                
                total_generated += 1
        
        # å„²å­˜ results.json
        results_json = self.output_dir / "controlnet_results.json"
        with open(results_json, "w", encoding="utf-8") as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        print(f"\n{'='*60}")
        print(f"âœ… ControlNet å¯¦é©—å®Œæˆï¼")
        print(f"{'='*60}")
        print(f"ğŸ“Š ç¸½å…±ç”Ÿæˆ: {total_generated} å¼µåœ–ç‰‡")
        print(f"â±ï¸  å¹³å‡ç”Ÿæˆæ™‚é–“: {np.mean([r['generation_time'] for r in self.results]):.2f}s")
        print(f"ğŸ’¾ çµæœå„²å­˜åœ¨: {self.output_dir}")
        print(f"ğŸ“„ JSON è¨˜éŒ„: {results_json}")
        print(f"{'='*60}")

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="Person C - ControlNet Experiments")
    parser.add_argument("--num_prompts", type=int, default=25,
                       help="Number of prompts to test (default: 25)")
    args = parser.parse_args()
    
    print("\nğŸ¯ Person C - ControlNet Experiment")
    print("Comparative Study of Text-to-Image Generation")
    print("="*60)
    
    experiment = ControlNetExperiment()
    experiment.run_experiments(num_prompts=args.num_prompts)
    
    print("\nğŸ‰ Done! Next step: Run evaluation.py")

if __name__ == "__main__":
    import numpy as np  # for average calculation
    main()